{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gilda Rech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "hqnl0AKVXIA4"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TNNnck-8RiFN"
   },
   "source": [
    "# Tutorial 1b: Softmax Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g1DV-MS2bxYq"
   },
   "source": [
    "**Question:** To have the logistic regressor output probabilities, they need to be processed through a softmax layer. Implement a softmax layer yourself. What numerical issues may arise in this layer? How can you solve them? Use the testing code to confirm you implemented it correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "RM9V8s2uRiFO"
   },
   "outputs": [],
   "source": [
    "logits = torch.rand((1, 20)) + 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Dj4X2PnOfK9W"
   },
   "outputs": [],
   "source": [
    "def bad_softmax(x: Tensor) -> Tensor:\n",
    "    return torch.exp(x) / torch.sum(torch.exp(logits), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X00svmZSRiFP",
    "outputId": "b2330de8-d7e6-4f44-dc67-5da6889d74f3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(nan)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(bad_softmax(logits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "UW5klZqGRiFP"
   },
   "outputs": [],
   "source": [
    "def good_softmax(x: Tensor) -> Tensor:\n",
    "    ###########################################################################\n",
    "    # TODO: Implement a more stable way to compute softmax                    #\n",
    "    ###########################################################################\n",
    "    x=(x-x.max())\n",
    "    return torch.exp(x) / torch.sum(torch.exp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CapxhrTITaXe",
    "outputId": "a69fc409-9468-4a8e-aaf4-623f99a09bee"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0024, 0.0013, 0.0015, 0.0018, 0.0013, 0.0015, 0.0023, 0.0025, 0.0033,\n",
       "         0.0055, 0.0053, 0.0015, 0.0023, 0.0044, 0.0012, 0.0024, 0.0049, 0.0029,\n",
       "         0.0023, 0.0023]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_softmax(logits)*good_softmax(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6ROb0PCQRiFQ",
    "outputId": "1a9c07be-fed0-456e-b471-21ea99dd2c44"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0000)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(good_softmax(logits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "F1udfr_Na8Xf"
   },
   "outputs": [],
   "source": [
    "p=torch.zeros(3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cxpAcYqrb4jJ",
    "outputId": "30c6f1d0-12d1-44bb-fe7c-f390ece6e25d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 1.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p[2, 2]=1\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4C_J5S0RScXJ"
   },
   "source": [
    "Because of numerical issues like the one you just experiences, PyTorch code typically uses a `LogSoftmax` layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lgStX-ctjIms"
   },
   "source": [
    "**Question [optional]:** PyTorch automatically computes the backpropagation gradient of a module for you. However, it can be instructive to derive and implement your own backward function. Try and implement the backward function for your softmax module and confirm that it is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "pJG3RLdcURlf"
   },
   "outputs": [],
   "source": [
    "def derivSoft(x:Tensor) ->Tensor:\n",
    "  leng=x.size()[0]\n",
    "  mat=[] #torch.zeros((leng, leng))\n",
    "  for i in range(leng):\n",
    "    for j in range(leng):\n",
    "      if i==j:\n",
    "        #print(good_softmax(x[i]).shape())\n",
    "        res=good_softmax(x[i].reshape(1,-1))*(1-good_softmax(x[i].reshape(1, -1)))\n",
    "      else:\n",
    "        res=-good_softmax(x[i])*good_softmax(x[j])\n",
    "      mat.append(res)\n",
    "  return mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "TxzwwokAcYn-"
   },
   "outputs": [],
   "source": [
    "logits1 = torch.rand((2, 20)) + 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LoMxMywGceyl",
    "outputId": "1894db44-76cf-4da5-abed-811bafb653e6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[0.0374, 0.0393, 0.0486, 0.0600, 0.0444, 0.0347, 0.0591, 0.0581, 0.0690,\n",
       "          0.0561, 0.0301, 0.0414, 0.0570, 0.0336, 0.0364, 0.0281, 0.0527, 0.0522,\n",
       "          0.0455, 0.0633]]),\n",
       " tensor([-0.0012, -0.0015, -0.0017, -0.0022, -0.0021, -0.0013, -0.0054, -0.0023,\n",
       "         -0.0025, -0.0026, -0.0022, -0.0022, -0.0038, -0.0025, -0.0014, -0.0024,\n",
       "         -0.0033, -0.0021, -0.0017, -0.0051]),\n",
       " tensor([-0.0012, -0.0015, -0.0017, -0.0022, -0.0021, -0.0013, -0.0054, -0.0023,\n",
       "         -0.0025, -0.0026, -0.0022, -0.0022, -0.0038, -0.0025, -0.0014, -0.0024,\n",
       "         -0.0033, -0.0021, -0.0017, -0.0051]),\n",
       " tensor([[0.0310, 0.0342, 0.0316, 0.0339, 0.0430, 0.0360, 0.0778, 0.0354, 0.0329,\n",
       "          0.0418, 0.0662, 0.0492, 0.0585, 0.0662, 0.0360, 0.0759, 0.0553, 0.0364,\n",
       "          0.0336, 0.0689]])]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "derivSoft(logits1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "YWXm0w2OeC2E"
   },
   "outputs": [],
   "source": [
    "from torch.autograd import backward, grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "2ktUYP_5ghNw"
   },
   "outputs": [],
   "source": [
    "logitx = torch.rand((2, 20)) + 100\n",
    "logitx.requires_grad=True\n",
    "logitx.sum().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KdYhO9BahRhT",
    "outputId": "c82add31-32f1-4bef-f42c-ebb736474630"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logitx.grad"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "convnet_tutorial_1b_Gilda Rech Bansimba.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
